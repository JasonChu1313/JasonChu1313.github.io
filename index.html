<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>朱思宇的博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="朱思宇的博客">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="朱思宇的博客">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="朱思宇的博客">
  
    <link rel="alternate" href="/atom.xml" title="朱思宇的博客" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">朱思宇的博客</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-distributed" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/09/03/distributed/" class="article-date">
  <time datetime="2017-09-03T15:37:50.000Z" itemprop="datePublished">2017-09-03</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/09/03/distributed/">分布式资源管理</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>DRM(分布式资源管理)<br>大型的分布式系统中存在很多的配置文件，分布式资源管理解决了配置文件同步更新的问题，不仅仅是配置文件，此技术还可以支持缓存数据的同步一致，下面将简单介绍一下基于消息机制的分布式资源管理系统。<br>1、    传统的配置同步问题：<br>配置文件作为静态的config.xml文件存储在各个节点上，不可动态改变，修改配置需要重新部署应用，在大型实时系统中很不友好不易扩展。</p>
<p>2、    缓存+单机DB：<br>将配置信息存储在缓存中，当修改了缓存后可以将信息同步到数据库中，每一次更新都要查询数据库不太现实。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/7058214-d913ab77888d5cfb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="缓存+单机DB.png"></p>
<p>3、    定时轮询技术<br>一台机器修改了数据库的配置信息后，其他机器定时轮询进行更新，轮询的时间设置是个关键，时间设置长了会导致数据长时间不同步，时间设置的短了会导致频繁访问数据库造成资源的浪费，所以该方法也不适合对于读多写少的分布式系统。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/7058214-0d957c57dc0f609e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="定时轮询技术.png"></p>
<p>4、    Drm Version1<br>基于配置中心的发布-订阅模型（publish-subscribe）Drm服务器是发布者，应用服务器是订阅者，Drm为应用的每一个配置项生成一个唯一标识的字符串，注册到配置中心，配置中实时将值推送给订阅者。但是这些配置值如果全部存在配置中心内存中会占用很大的空间因此也具有一定的缺点。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/7058214-c467c118bc9f2bce.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Drm1.png"></p>
<p>5、    DRM Version2<br>配置发生更变后通知DrmServer，相应的配置值直接写入到DrmData缓存中，然后将指令发布到配置中心中，配置中心不存储数据而是将指令push到应用服务器端，应用服务器在接到推送指令后向缓存中pull相应的指令。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/7058214-0fabd098da5de0ff.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="4.png"></p>
<p>总结：DRM主要用于有读多写少任务的分布式系统中，其保证了最终一致性，且必须由后台去调用，如果报漏给前端，会造成大量调用，给配置中心带来压力。其原理是基于发布订阅模型和消息的数据同步，应用的场景不仅在配置文件中，例如：集群中各个节点初始化后需要将将数据库的内容缓存到本机，但是如果对数据库内容进行了改变，则需要有机制来通知各节点进行缓存的更新，drm在这种场景下可以很好的发挥作用。</p>
<p>PS：写文章用心良苦，转载请注明出处</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/09/03/distributed/" data-id="cj8bruss20002881n0jbnl3dh" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-tensor" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/08/05/tensor/" class="article-date">
  <time datetime="2017-08-05T11:59:00.000Z" itemprop="datePublished">2017-08-05</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/08/05/tensor/">TensorFlow Tutorial-1</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="1、Why-TensorFlow"><a href="#1、Why-TensorFlow" class="headerlink" title="1、Why TensorFlow?"></a>1、Why TensorFlow?</h1><p>网上有关介绍太多了，我就不多说了，这里主要注重使用。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/7058214-5fecb3836a99ad46.PNG?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Intro.PNG"></p>
<p><img src="http://upload-images.jianshu.io/upload_images/7058214-bfb78a2ee08d6c22.PNG?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="github.PNG"></p>
<h1 id="2、Programing-model"><a href="#2、Programing-model" class="headerlink" title="2、Programing model"></a>2、Programing model</h1><h2 id="2-1、Big-Idea："><a href="#2-1、Big-Idea：" class="headerlink" title="2.1、Big Idea："></a>2.1、Big Idea：</h2><p>将数值的计算转化为图（computational graph），任何tensorflow的计算都是基于图的。</p>
<h2 id="2-2、Graph-Nodes："><a href="#2-2、Graph-Nodes：" class="headerlink" title="2.2、Graph Nodes："></a>2.2、Graph Nodes：</h2><p>图中的结点是有输入和输出的操作（operations），input的数量可以任意，output只有一个。</p>
<h2 id="2-3、Graph-Edges："><a href="#2-3、Graph-Edges：" class="headerlink" title="2.3、Graph Edges："></a>2.3、Graph Edges：</h2><p> 图的边是在结点见浮动的张量（tensors），tensors可以理解为n-维数组。</p>
<h2 id="2-4、Advantages："><a href="#2-4、Advantages：" class="headerlink" title="2.4、Advantages："></a>2.4、Advantages：</h2><p>使用flow graphs作为deep learning framework的优点是可以通过简单少量的operations来构建复杂模型，使梯度的计算容易很多。当你在编写比较大的模型时，自动微分将会帮助到你。</p>
<h2 id="2-5、Another-Way-To-Think-It："><a href="#2-5、Another-Way-To-Think-It：" class="headerlink" title="2.5、Another Way To Think It："></a>2.5、Another Way To Think It：</h2><p>每一个operation可以理解为在某一点可以执行的函数。</p>
<h2 id="2-6、举个详细使用的栗子："><a href="#2-6、举个详细使用的栗子：" class="headerlink" title="2.6、举个详细使用的栗子："></a>2.6、举个详细使用的栗子：</h2><p>下面这个图展示了只有一个隐藏层的神经网络在Tensorflow中的计算，我们以Relu作为激活函数。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/7058214-f75959626599e7ad.PNG?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Nodes.PNG"></p>
<p><img src="http://upload-images.jianshu.io/upload_images/7058214-5d1114cd67b83f36.PNG?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="ReLu Function.PNG"></p>
<ul>
<li>W：  待训练的参数</li>
<li>X：   input</li>
<li>b：   bias<br>下面将介绍一下上图中出现的几个结点：<h3 id="1、Variables："><a href="#1、Variables：" class="headerlink" title="1、Variables："></a>1、Variables：</h3>W 和 b 参数作为TensorFlow中的Variables，在训练的过程中你需要调整这些参数，使得你的loss function最小，这些变量是有状态的结点，在图中多种的计算结点之间保持他们的状态，所谓保持状态就是指它们的值会被存下来，因此想要复原数据很容易，并且可以随时输出他们当前的值（current value），这些变量还有一些其他的features，可以在训练或者训练结束后持久化到disk中，因此可以允许不同的公司不同的组织去使用这些大型模型训练好的参数，并且默认进行梯度更新。<br>W 和 b这些变量也是operations。</li>
</ul>
<h3 id="2、Placeholders："><a href="#2、Placeholders：" class="headerlink" title="2、Placeholders："></a>2、Placeholders：</h3><p>是一些在执行的过程中才会被赋值的结点，如果你网络的input 需要依赖一些其他外界的数据。<br>比如你不想用真实的值来计算。placeholders是你在训练过程中可以加入数据的地方。对于placeholders，我们不用对其进行任何初始化，我们只定义一个data type，并且赋值一个给定大小的tensor，我们的计算图就可以知道怎么去计算，甚至不用存储任何的数据。</p>
<h3 id="3、Mathematical-operations："><a href="#3、Mathematical-operations：" class="headerlink" title="3、Mathematical operations："></a>3、Mathematical operations：</h3><p>用于矩阵的乘法，加法，ReLu函数的计算。</p>
<h3 id="4、废话少说，上代码！！！-："><a href="#4、废话少说，上代码！！！-：" class="headerlink" title="4、废话少说，上代码！！！ ："></a>4、废话少说，上代码！！！ ：</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"># 导入tensorflow包</div><div class="line">import tensorflow as tf</div><div class="line"># 创建一个有100个值的vector，作为bias, 默认为0</div><div class="line">b=tf.Variable(tf.zeros((100,)))</div><div class="line"># 创建并出示化权重，一个784*100 的矩阵，矩阵的初始值在-1到1之间</div><div class="line">W=tf.Variable(tf.random_uniform((784,100),-1,1))</div><div class="line">#为输入创建一个placeholder，不需要任何数据，只需要定义数据类型为一个32位浮点数，shape 为100*784</div><div class="line">x=tf.placeholder(tf.float32,(100,784))</div><div class="line"># tensorflow mathematical operations</div><div class="line">h=tf.nn.relu(tf.matmul(x,W)+b)</div></pre></td></tr></table></figure>
<p>关于h我想说：和numpy中很像，就是调用了tensorflow mathematical operations，我们没有真的乘某个数值，而仅仅在图中创建了一个符号来表示他，所以你不能输出该值，因为x只是一个placeholder，没有任何真值。我们现在只为我们的model创建了一个骨架。</p>
<h3 id="5、说好的图呢-："><a href="#5、说好的图呢-：" class="headerlink" title="5、说好的图呢 ："></a>5、说好的图呢 ：</h3><p>看了半天，这不和numpy手撸一样吗，其实作为程序员我们只要心里有着种抽象的概念就好，底层确实是以这种结点来实现的，如果你想看到，可以调用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">tf.get_default_graph().get_operations()</div></pre></td></tr></table></figure></p>
<p>你将会看到如下内容：</p>
<p><img src="http://upload-images.jianshu.io/upload_images/7058214-79d6240b234f8219.PNG?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Absta.PNG"></p>
<h3 id="6、怎么跑这个例子呢？-："><a href="#6、怎么跑这个例子呢？-：" class="headerlink" title="6、怎么跑这个例子呢？ ："></a>6、怎么跑这个例子呢？ ：</h3><p>目前为止，我们已经定义了一个graph，我们需要把这个graph部署到一个session中，一个session可以绑定到一个具体的执行环境中（CPU或者GPU）</p>
<p>接着刚才的代码，我们在后面补充三行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">import numpy as np</div><div class="line">import tensorflow as tf</div><div class="line">b=tf.Variable(tf.zeros((100,)))</div><div class="line">W=tf.Variable(tf.random_uniform((784,100),-1,1))</div><div class="line">x=tf.placeholder(tf.float32,(100,784))</div><div class="line">h=tf.nn.relu(tf.matmul(x,W)+b)</div><div class="line"></div><div class="line">#创建session对象，初始化相关的参数</div><div class="line">sess=tf.Session()</div><div class="line"># initialize b 和 w</div><div class="line">sess.run(tf.initialize_all_variables())</div><div class="line"># 第一个参数是图中结点的输出，第二个参数是给placeholder赋的值，是一个map，定义每个结点的具体值</div><div class="line">sess.run(h,&#123;x : np.random.random(100,784)&#125;)</div></pre></td></tr></table></figure>
<p>更多的关于Session的使用方法:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line">#自己创建一个session,不使用默认的session,使用完记得关了</div><div class="line">sess=tf.Session()</div><div class="line">sess=tf.run(train_step)</div><div class="line">sess.close()</div><div class="line"></div><div class="line"></div><div class="line">with tf.Session() as sess:</div><div class="line">    #使用这个创建的session计算结果</div><div class="line">    sess.run(train_step)</div><div class="line">    #不用close,with体帮我们进行资源的回收</div><div class="line"></div><div class="line">#with体使用默认的session</div><div class="line">sess=tf.Session()</div><div class="line">with sess.as_default():</div><div class="line">    print(train_step.eval())</div><div class="line"></div><div class="line"></div><div class="line">#也是使用默认的session</div><div class="line">sess=tf.Session()</div><div class="line">print(train_step.eval(session=sess))</div><div class="line"></div><div class="line"></div><div class="line">#定义一个可交互式的session,自动将会话注册为默认会话</div><div class="line">sess=tf.InteractiveSession()</div><div class="line">train_step.eval()</div><div class="line">sess.close()</div><div class="line"></div><div class="line"></div><div class="line">#用自己的参数配置session</div><div class="line">config=tf.ConfigProto(allow_aoft_placement=True,</div><div class="line">                      log_device_placement=True)</div><div class="line">sess1=tf.InteractiveSession(config=config)</div><div class="line">sess2=tf.Session(config=config)</div></pre></td></tr></table></figure></p>
<h3 id="7、损失函数的创建-："><a href="#7、损失函数的创建-：" class="headerlink" title="7、损失函数的创建 ："></a>7、损失函数的创建 ：</h3><p>通过prediction 和 labels 创建loss node<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"># neural network的最后一步，用softmax做一个逻辑回归</div><div class="line">prediction=tf.nn.softmax(...)</div><div class="line">label=tf.placeholder(tf.float32,[100,10])</div><div class="line"># 损失函数，用label乘上logP在列上的值</div><div class="line">cross_entropy=-tf.reduce_sum(label* tf.log(prediction),axis=1)</div></pre></td></tr></table></figure></p>
<h3 id="8、如何计算梯度？："><a href="#8、如何计算梯度？：" class="headerlink" title="8、如何计算梯度？："></a>8、如何计算梯度？：</h3><p>tf.train.GradientDescentOptimizer创建了一个Optimizer是TensorFlow中定义的一个抽象类，它的每个子类，可以作为一个特定的学习算法，默认是梯度下降。在我们的图上面加了一个optimization operation，当我们执行这个train_step方法时（sess.run(train_step,feed_dict={x: batch_x, label: batch_label})）,将会应用所有的梯度到模型中的变量中。这是因为minimize函数做了两件事情，首先是计算cross_entropy的梯度，然后进行梯度更新。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># 梯度下降，learning rate 为0.5，minimize方法的参数是一个需要被梯度下降的结点。</div><div class="line">train_step= tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)</div></pre></td></tr></table></figure>
<h3 id="8、训练模型？："><a href="#8、训练模型？：" class="headerlink" title="8、训练模型？："></a>8、训练模型？：</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">sess=tf.Session()</div><div class="line">sess.run(tf.initialize_all_variables())</div><div class="line"># 创建一个learning schedule, iterate 1000 次</div><div class="line">for i in range(1000):</div><div class="line">        batch_x, batch_label  = data.next_batch()</div><div class="line">        sess.run(train_step,feed_dict=&#123;x: batch_x, label: batch_label&#125;)</div></pre></td></tr></table></figure>
<h1 id="3、变量共享"><a href="#3、变量共享" class="headerlink" title="3、变量共享"></a>3、变量共享</h1><p>当你在使用Tensorflow时，你想在一个地方初始化所有的变量，比如我想多次实例化我的graph或者我想在GPU集群上训练，我们需要共享变量。有以下两个解决方案：<br>其中一个方法是创建一个map，在需要使用的地方调用key获得value。但缺点是它大破了封装的思想。<br>TensorFlow的variable scope解决了这个问题，它为我们提供了一个提供了一个命名空间，避免了冲突。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">with tf.variable_scope(&quot;hello world&quot;):</div><div class="line">              v=tf.get_variable(&quot;v&quot;,shape=[1])</div><div class="line"># v.name== &quot; hello world/v:0&quot;</div><div class="line">with tf.variable_scope(&quot;hello world&quot; reuse=True):</div><div class="line">              v=tf.get_variable(&quot;v&quot;,shape=[1])</div><div class="line"># 可以找到共享的变量v</div><div class="line">with tf.variable_scope(&quot;hello world&quot; reuse=False):</div><div class="line">              v=tf.get_variable(&quot;v&quot;,shape=[1])</div><div class="line"># CRASH hello world/v:0 已经存在了</div></pre></td></tr></table></figure></p>
<h1 id="4、官方demo-（Official-Demo）："><a href="#4、官方demo-（Official-Demo）：" class="headerlink" title="4、官方demo （Official Demo）："></a>4、官方demo （Official Demo）：</h1><p>MNIST手写体识别</p>
<h2 id="4-1、基于Softmax逻辑回归"><a href="#4-1、基于Softmax逻辑回归" class="headerlink" title="4.1、基于Softmax逻辑回归"></a>4.1、基于Softmax逻辑回归</h2><p>利用softmax regression,训练一个手写体分类：<br><figure class="highlight plain"><figcaption><span>for downloading and reading MNIST data."""</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line">from __future__ import absolute_import</div><div class="line">from __future__ import division</div><div class="line">from __future__ import print_function</div><div class="line"></div><div class="line">import gzip</div><div class="line">import os</div><div class="line">import tempfile</div><div class="line"></div><div class="line">import numpy</div><div class="line">from six.moves import urllib</div><div class="line">from six.moves import xrange  # pylint: disable=redefined-builtin</div><div class="line">import tensorflow as tf</div><div class="line">from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets</div><div class="line">from tensorflow.examples.tutorials.mnist import input_data</div><div class="line">mnist = input_data.read_data_sets(&quot;MNIST_data/&quot;, one_hot=True)</div><div class="line"># 定义一个placeholder,</div><div class="line">x = tf.placeholder(tf.float32, [None, 784])</div><div class="line">W = tf.Variable(tf.zeros([784, 10]))</div><div class="line">b = tf.Variable(tf.zeros([10]))</div><div class="line">y = tf.nn.softmax(tf.matmul(x, W) + b)</div><div class="line">#定义一个用于存储正确标示的占位符</div><div class="line">y_=tf.placeholder(&quot;float&quot;,[None,10])</div><div class="line">#交叉熵损失函数</div><div class="line">cross_entropy=-tf.reduce_sum(y_*tf.log(y))</div><div class="line">#梯度下降进行训练</div><div class="line">train_step=tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)</div><div class="line">init=tf.initialize_all_variables()</div><div class="line">sess=tf.Session()</div><div class="line">sess.run(init)</div><div class="line">#随机梯度下降</div><div class="line">for i in range(1000):</div><div class="line">    batch_xs, batch_ys=mnist.train.next_batch(100)</div><div class="line">    print(sess.run(train_step,feed_dict=&#123;x:batch_xs,y_:batch_ys&#125;))</div><div class="line">correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))</div><div class="line">accuracy=tf.reduce_mean(tf.cast(correct_prediction,&quot;float&quot;))</div><div class="line">print(sess.run(accuracy, feed_dict=&#123;x: mnist.test.images, y_: mnist.test.labels&#125;))</div></pre></td></tr></table></figure></p>
<h2 id="4-2、基于CNN神经网络"><a href="#4-2、基于CNN神经网络" class="headerlink" title="4.2、基于CNN神经网络"></a>4.2、基于CNN神经网络</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div></pre></td><td class="code"><pre><div class="line"># 利用CNN,训练一个手写体分类</div><div class="line">&quot;&quot;&quot;Functions for downloading and reading MNIST data.&quot;&quot;&quot;</div><div class="line">from __future__ import absolute_import</div><div class="line">from __future__ import division</div><div class="line">from __future__ import print_function</div><div class="line"></div><div class="line">import gzip</div><div class="line">import os</div><div class="line">import tempfile</div><div class="line"></div><div class="line">import numpy</div><div class="line">from six.moves import urllib</div><div class="line">from six.moves import xrange  # pylint: disable=redefined-builtin</div><div class="line">import tensorflow as tf</div><div class="line">from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets</div><div class="line">from tensorflow.examples.tutorials.mnist import input_data</div><div class="line"></div><div class="line"># 将系统默认的session作ion</div><div class="line">sess = tf.InteractiveSession()</div><div class="line">mnist = input_data.read_data_sets(&quot;MNIST_data/&quot;, one_hot=True)</div><div class="line"># 正确答案</div><div class="line">y_ = tf.placeholder(&apos;float&apos;, [None, 10])</div><div class="line"></div><div class="line"></div><div class="line"># 定义函数用于初始化权值,和bias</div><div class="line">def weight_initialize(shape):</div><div class="line">    # 标准差为一,初始化权值</div><div class="line">    initial = tf.truncated_normal(shape, stddev=0.1)</div><div class="line">    return tf.Variable(initial)</div><div class="line"></div><div class="line"></div><div class="line">def bias_variable(shape):</div><div class="line">    initail = tf.constant(0.1, shape=shape)</div><div class="line">    return tf.Variable(initail)</div><div class="line"></div><div class="line"></div><div class="line">x = tf.placeholder(&apos;float&apos;, [None, 784])</div><div class="line"></div><div class="line"></div><div class="line"># 卷积</div><div class="line">def conv2d(x, W):</div><div class="line">    #tf.nn.conv2d提供了一个非常方便的函数来实现卷积层向前传播的算法,这个函数的第一个输入为</div><div class="line">    #当前层节点矩阵,这个矩阵是一个四维矩阵,后面的三个维度对应一个节点矩阵,第一个维度对应一个</div><div class="line">    #输入batch.比如在输入层,input[0,:,:,:]表示第一张图片,input[1,:,:,:]表示第张图片二,tf.nn.conv2d</div><div class="line">    #第二个参数提供了卷积层的权重,第三个参数为步长,步长第一维,和最后一维固定是1,最后一个参数是填充方法</div><div class="line">    #SAME表示全0填充,VALID表示不添加</div><div class="line">    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=&apos;SAME&apos;)</div><div class="line"></div><div class="line"></div><div class="line"># 池化</div><div class="line">def max_pool_2x2(x):</div><div class="line">    #ksize提供了过滤器的大小为2*2</div><div class="line">    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=&apos;SAME&apos;)</div><div class="line"></div><div class="line"></div><div class="line"># 卷积层第一层</div><div class="line">W_conv1 = weight_initialize([5, 5, 1, 32])</div><div class="line">b_conv1 = bias_variable([32])</div><div class="line">x_image = tf.reshape(x, [-1, 28, 28, 1])</div><div class="line"># 卷积层第一层的relu和池化</div><div class="line">h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)</div><div class="line">h_pool1 = max_pool_2x2(h_conv1)</div><div class="line"># 5*5*32</div><div class="line"># 卷积层第二层</div><div class="line">W_conv2 = weight_initialize([5, 5, 32, 64])</div><div class="line">b_conv2 = bias_variable([64])</div><div class="line"># 卷积层第二层的relu和池化</div><div class="line">h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)</div><div class="line">h_pool2 = max_pool_2x2(h_conv2)</div><div class="line"># 全连接层的weight和bias</div><div class="line">W_fc1 = weight_initialize([7 * 7 * 64, 1024])</div><div class="line">b_fc1 = bias_variable([1024])</div><div class="line"># output层</div><div class="line">h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])</div><div class="line">h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)</div><div class="line"></div><div class="line"># 使用dropout防止过拟合</div><div class="line"># 过拟合概率</div><div class="line">keep_prob = tf.placeholder(&quot;float&quot;)</div><div class="line">h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)</div><div class="line"># 1024个神经元*10个输出</div><div class="line">W_fc2 = weight_initialize([1024, 10])</div><div class="line">b_fc2 = bias_variable([10])</div><div class="line">y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2))</div><div class="line"># 定义一个损失函数</div><div class="line">cross_entropy = -tf.reduce_sum(y_ * tf.log(y_conv))</div><div class="line">train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)</div><div class="line">correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))</div><div class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction,&quot;float&quot;))</div><div class="line"># 初始化所有变量</div><div class="line">sess.run(tf.initialize_all_variables())</div><div class="line">for i in range(2000):</div><div class="line">    batch = mnist.train.next_batch(50)</div><div class="line">    if i % 100 == 0:</div><div class="line">        train_accuracy = accuracy.eval(feed_dict=&#123;</div><div class="line">            x: batch[0], y_: batch[1], keep_prob: 1.0</div><div class="line">        &#125;)</div><div class="line">        print(&quot;step %d, train accuracy %g&quot; % (i, train_accuracy))</div><div class="line">    train_step.run(feed_dict=&#123;x: batch[0], y_: batch[1], keep_prob: [0.5]&#125;)</div><div class="line"></div><div class="line">print(&quot;test accuracy %g&quot; % accuracy.eval(feed_dict=&#123;</div><div class="line">    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0&#125;))</div></pre></td></tr></table></figure>
<p>训练结果如下：</p>
<p><img src="http://upload-images.jianshu.io/upload_images/7058214-44a150cc63f80034.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="result.png"></p>
<p>别着急，我还要再废话一下：对于上面的实现，我们发现在网络层数增多的情况下，变量的命名可能会重复，造成错误，为了保证代码的可读性，我们可以采用如下的方式表示一个层的计算：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line">#第一个卷积层的参数</div><div class="line">CONV1_DEEP=32</div><div class="line">CONV1_SIZE=5</div><div class="line">NUM_CHANNAL=1</div><div class="line">#第二个卷积层的参数</div><div class="line">CONV2_DEEP=64</div><div class="line">CONV2_SIZE=5</div><div class="line">#全连结层的节点</div><div class="line">FC_SIZE=512</div><div class="line"></div><div class="line">#第一个卷积层的实现</div><div class="line">with tf.name_scope(&quot;Layer1-conv1&quot;):</div><div class="line">    #定义权值,实际weight的名称为Layer1-conv1/weight</div><div class="line">    weight=tf.get_variable(&quot;weight&quot;,[CONV1_SIZE,CONV1_SIZE,NUM_CHANNAL,CONV1_DEEP],</div><div class="line">                           initializer=tf.truncated_normal(stddev=0.1))</div><div class="line">    #定义bias</div><div class="line">    conv1_bias=tf.get_variable(&quot;bias&quot;,[CONV1_DEEP],initializer=tf.constant_initializer(0.1))</div><div class="line">    conv1=tf.conv2d(x, weight, strides=[1, 1, 1, 1], padding=&apos;SAME&apos;)</div><div class="line">    relu1=tf.nn.relu(tf.matmul(x,weight))</div><div class="line"></div><div class="line"></div><div class="line">#第一个卷积层的池化</div><div class="line">with tf.name_scope(&quot;Max-pooling&quot;):</div><div class="line">    pool=tf.nn.max_pool(relu1,ksize=[1,1,1,1],strides=[1,2,2,1],padding=&apos;SAME&apos;)</div><div class="line"></div><div class="line"></div><div class="line">#如果在构造大型网络的过程中，如果一个层用6行代码，还是太臃肿，这时候可以使用更简洁的</div><div class="line">#TensorFlow-Slim工具来处理</div><div class="line">net=slim.conv2d(input,32,[3,3])</div></pre></td></tr></table></figure></p>
<h1 id="5、总结："><a href="#5、总结：" class="headerlink" title="5、总结："></a>5、总结：</h1><ul>
<li>TensorFlow 每个结点都对应着梯度操作</li>
<li>Computational graphy 很容易backwards每一个结点。</li>
<li>这些都是自动完成的。</li>
<li>TensorFlow也把复杂的计算放在python之外完成，但是为了避免前面说的那些开销，它做了进一步完善。Tensorflow不单独地运行单一的复杂计算，而是让我们可以先用图描述一系列可交互的计算操作，然后全部一起在Python之外运行。</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/08/05/tensor/" data-id="cj8bruss40003881n30vtbfaj" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-callback" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/08/03/callback/" class="article-date">
  <time datetime="2017-08-03T15:34:36.000Z" itemprop="datePublished">2017-08-03</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/08/03/callback/">JAVA回调机制(CallBack)详解</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>1、前言：<br>最近在杭州阿里巴巴蚂蚁金服AI部门实习，负责分布式系统的研究与开发，在学习和实践的过程中有很多地方用到了回调函数的思想，想借此机会和大家分享一下回调的应用场景和回调函数的设计思想。<br>2、什么是回调函数（Callback Function）:<br>回调的应用场景非常广泛，在spring中可以看到很多应用了回调的地方，以调用相应的库函数为例子，当程序跑起来时，一般情况下，应用程序（application program）会时常通过API调用库里所预先备好的函数。很常见的函数调用如：<br>a.func(Param)<br>但是有些库函数（library function）却要求应用先传给它一个函数，好在合适的时候调用，以完成目标任务。这个被传入的、后又被调用的函数就称为回调函数（callback function），这样解释估计还是比较晦涩，下面我讲用一个简单通俗的例子来解释这一术语。<br>3、举个栗子（回调的应用场景）<br>网上解释回调的例子有很多，大多数使用的是“算数问题”，我觉得这个解释是比较通俗易懂的，但是如果只是单单看这种场景，对于工程应用的使用场景还不是很直观，我更多的是想从实际工程应用的角度来阐述这个概念，因此如果想有个大致的概念可以参考下面这个博客的例子：<br>请戳这里：一个通俗有趣的回调例子</p>
<p>应用场景如下：<br>A类在内存中维护了一组词表，A类的定义如下：</p>
<p>定义一个泛形接口，对于返回值和参数都十分的灵活：</p>
<p>应用场景：</p>
<p>好了，上面简单的三个类就是一个回调的应用，所谓的回调函数就是process函数这个函数是被传入后又被调用的，就我自己的理解而言回调有以下优点：<br>1、非常的灵活，用户可以在匿名内部类中定义自己的实现方法。<br>2、回调相当于c++中的参数里的函数指针，可以在实现了CallbackInterface接口的类中，或者匿名内部类中改变其他类中的成员变量。<br>3、回调还出现在button中的监听器里，安卓代码中形式如下：</p>
<p>4、其实定义一个新的线程然后在run方法中实现相应的逻辑也是一种回调。<br>5、回调的概念其实不难，难在怎么在设计中灵活的运用<br>如果大家有什么问题可以直接在评论区问我，我们可以相互讨论共同进步。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/08/03/callback/" data-id="cj8brusrv0000881nl8g6yw2f" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-class" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/08/02/class/" class="article-date">
  <time datetime="2017-08-02T15:40:28.000Z" itemprop="datePublished">2017-08-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/08/02/class/">ClassLoader和类加载机制</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="1、背景"><a href="#1、背景" class="headerlink" title="1、背景"></a>1、背景</h1><h5 id="最近在做项目的过程中，由于系统需要提供一个对外接口，使系统使用者可以以脚本的形式提交自己的代码，每个用户可以在系统规范的约束下编写脚本，由系统去执行用户的代码，实现了热部署。什么叫热部署呢？简单来说就是把代码当成U盘或者外设一样即插即用，每个用户可以维护自己的解决方案（也就是一段脚本，一个单独的类），在更新修改解决方案的过程中而不需要重新编译启动整个系统。我们采用的方案就是GroovyClassLoader，我主要讲一讲自己对ClassLoader的理解和使用。"><a href="#最近在做项目的过程中，由于系统需要提供一个对外接口，使系统使用者可以以脚本的形式提交自己的代码，每个用户可以在系统规范的约束下编写脚本，由系统去执行用户的代码，实现了热部署。什么叫热部署呢？简单来说就是把代码当成U盘或者外设一样即插即用，每个用户可以维护自己的解决方案（也就是一段脚本，一个单独的类），在更新修改解决方案的过程中而不需要重新编译启动整个系统。我们采用的方案就是GroovyClassLoader，我主要讲一讲自己对ClassLoader的理解和使用。" class="headerlink" title="最近在做项目的过程中，由于系统需要提供一个对外接口，使系统使用者可以以脚本的形式提交自己的代码，每个用户可以在系统规范的约束下编写脚本，由系统去执行用户的代码，实现了热部署。什么叫热部署呢？简单来说就是把代码当成U盘或者外设一样即插即用，每个用户可以维护自己的解决方案（也就是一段脚本，一个单独的类），在更新修改解决方案的过程中而不需要重新编译启动整个系统。我们采用的方案就是GroovyClassLoader，我主要讲一讲自己对ClassLoader的理解和使用。"></a>最近在做项目的过程中，由于系统需要提供一个对外接口，使系统使用者可以以脚本的形式提交自己的代码，每个用户可以在系统规范的约束下编写脚本，由系统去执行用户的代码，实现了热部署。什么叫热部署呢？简单来说就是把代码当成U盘或者外设一样即插即用，每个用户可以维护自己的解决方案（也就是一段脚本，一个单独的类），在更新修改解决方案的过程中而不需要重新编译启动整个系统。我们采用的方案就是GroovyClassLoader，我主要讲一讲自己对ClassLoader的理解和使用。</h5><h1 id="2、类加载与类加载器"><a href="#2、类加载与类加载器" class="headerlink" title="2、类加载与类加载器"></a>2、类加载与类加载器</h1><h3 id="类加载："><a href="#类加载：" class="headerlink" title="类加载："></a>类加载：</h3><h5 id="类加载的过程就是将Class文件中描述的各种信息加载到虚拟机中，供程序后期运行和使用的。"><a href="#类加载的过程就是将Class文件中描述的各种信息加载到虚拟机中，供程序后期运行和使用的。" class="headerlink" title="类加载的过程就是将Class文件中描述的各种信息加载到虚拟机中，供程序后期运行和使用的。"></a>类加载的过程就是将Class文件中描述的各种信息加载到虚拟机中，供程序后期运行和使用的。</h5><h5 id="类加载的生命周期主要分为五个步骤："><a href="#类加载的生命周期主要分为五个步骤：" class="headerlink" title="类加载的生命周期主要分为五个步骤："></a>类加载的生命周期主要分为五个步骤：</h5><h4 id="1、加载："><a href="#1、加载：" class="headerlink" title="1、加载："></a>1、加载：</h4><h5 id="通过一个类的全限定名来获取描述此类的二进制字节流"><a href="#通过一个类的全限定名来获取描述此类的二进制字节流" class="headerlink" title="通过一个类的全限定名来获取描述此类的二进制字节流"></a>通过一个类的全限定名来获取描述此类的二进制字节流</h5><h5 id="将这个字节流所代表的静态存储结构转化为方法去的运行时数据结构"><a href="#将这个字节流所代表的静态存储结构转化为方法去的运行时数据结构" class="headerlink" title="将这个字节流所代表的静态存储结构转化为方法去的运行时数据结构"></a>将这个字节流所代表的静态存储结构转化为方法去的运行时数据结构</h5><h5 id="在内存中生成一个代表这个类的java-lang-Class-对象，作为方法区的各种数据类型的入口"><a href="#在内存中生成一个代表这个类的java-lang-Class-对象，作为方法区的各种数据类型的入口" class="headerlink" title="在内存中生成一个代表这个类的java.lang.Class 对象，作为方法区的各种数据类型的入口"></a>在内存中生成一个代表这个类的java.lang.Class 对象，作为方法区的各种数据类型的入口</h5><h4 id="2、验证"><a href="#2、验证" class="headerlink" title="2、验证"></a>2、验证</h4><h5 id="为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害到自身的安全。包括文件格式验证，元数据验证，字节码验证，符号引用验证。"><a href="#为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害到自身的安全。包括文件格式验证，元数据验证，字节码验证，符号引用验证。" class="headerlink" title="为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害到自身的安全。包括文件格式验证，元数据验证，字节码验证，符号引用验证。"></a>为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害到自身的安全。包括文件格式验证，元数据验证，字节码验证，符号引用验证。</h5><h4 id="3、准备"><a href="#3、准备" class="headerlink" title="3、准备"></a>3、准备</h4><h5 id="为变量分配内存，设置类变量的初始值。"><a href="#为变量分配内存，设置类变量的初始值。" class="headerlink" title="为变量分配内存，设置类变量的初始值。"></a>为变量分配内存，设置类变量的初始值。</h5><h4 id="4、解析"><a href="#4、解析" class="headerlink" title="4、解析"></a>4、解析</h4><h5 id="将常量池中的符号应用替代为直接引用。"><a href="#将常量池中的符号应用替代为直接引用。" class="headerlink" title="将常量池中的符号应用替代为直接引用。"></a>将常量池中的符号应用替代为直接引用。</h5><h4 id="5、初始化"><a href="#5、初始化" class="headerlink" title="5、初始化"></a>5、初始化</h4><h5 id="是类加载生命周期的最后一个过程，执行类中定义的java程序代码"><a href="#是类加载生命周期的最后一个过程，执行类中定义的java程序代码" class="headerlink" title="是类加载生命周期的最后一个过程，执行类中定义的java程序代码"></a>是类加载生命周期的最后一个过程，执行类中定义的java程序代码</h5><p>该过程如图所示:<br><img src="https://private-alipayobjects.alipay.com/alipay-rmsdeploy-image/skylark/gif/34855/28c473160c027e54.gif" alt="0_1319366219Na16.gif"> </p>
<h3 id="类加载器："><a href="#类加载器：" class="headerlink" title="类加载器："></a>类加载器：</h3><h5 id="在前面的类加载过程中，大部分动作都是完全由虚拟机主导和控制的。而类加载器使得用户可以在加载的过程中参与进来，结合前面的内容，类加载器就是将“通过一个类的全限定名来获取描述此类的二进制字节流”这个动作放到java虚拟机外部来实现。将主动权交给程序猿。"><a href="#在前面的类加载过程中，大部分动作都是完全由虚拟机主导和控制的。而类加载器使得用户可以在加载的过程中参与进来，结合前面的内容，类加载器就是将“通过一个类的全限定名来获取描述此类的二进制字节流”这个动作放到java虚拟机外部来实现。将主动权交给程序猿。" class="headerlink" title="在前面的类加载过程中，大部分动作都是完全由虚拟机主导和控制的。而类加载器使得用户可以在加载的过程中参与进来，结合前面的内容，类加载器就是将“通过一个类的全限定名来获取描述此类的二进制字节流”这个动作放到java虚拟机外部来实现。将主动权交给程序猿。"></a>在前面的类加载过程中，大部分动作都是完全由虚拟机主导和控制的。而类加载器使得用户可以在加载的过程中参与进来，结合前面的内容，类加载器就是将“通过一个类的全限定名来获取描述此类的二进制字节流”这个动作放到java虚拟机外部来实现。将主动权交给程序猿。</h5><h5 id="类加载器和这个类本身确定了其在java虚拟机中的唯一性，每一个类加载器都有一个独立的类命名空间，也就意味着，如果比较两个类是否相等，只有在这两个类是由同一个类加载器加载的前提下才有意义，否则，即使这两个类来源于同一个Class文件，被同一个虚拟机加载，只要加载他们的类加载器不同，那么这两个类就注定不相同。"><a href="#类加载器和这个类本身确定了其在java虚拟机中的唯一性，每一个类加载器都有一个独立的类命名空间，也就意味着，如果比较两个类是否相等，只有在这两个类是由同一个类加载器加载的前提下才有意义，否则，即使这两个类来源于同一个Class文件，被同一个虚拟机加载，只要加载他们的类加载器不同，那么这两个类就注定不相同。" class="headerlink" title="类加载器和这个类本身确定了其在java虚拟机中的唯一性，每一个类加载器都有一个独立的类命名空间，也就意味着，如果比较两个类是否相等，只有在这两个类是由同一个类加载器加载的前提下才有意义，否则，即使这两个类来源于同一个Class文件，被同一个虚拟机加载，只要加载他们的类加载器不同，那么这两个类就注定不相同。"></a>类加载器和这个类本身确定了其在java虚拟机中的唯一性，每一个类加载器都有一个独立的类命名空间，也就意味着，如果比较两个类是否相等，只有在这两个类是由同一个类加载器加载的前提下才有意义，否则，即使这两个类来源于同一个Class文件，被同一个虚拟机加载，只要加载他们的类加载器不同，那么这两个类就注定不相同。</h5><p>java的类加载器:<br><img src="https://private-alipayobjects.alipay.com/alipay-rmsdeploy-image/skylark/gif/34855/8f7bfafb8c0edde6.gif" alt="0_1319366276S7Uf.gif"> </p>
<h4 id="1、Bootstrap-Class-Loader：负责加载JAVA-HOME-lib目录下或-Xbootclasspath指定目录的jar包；"><a href="#1、Bootstrap-Class-Loader：负责加载JAVA-HOME-lib目录下或-Xbootclasspath指定目录的jar包；" class="headerlink" title="1、Bootstrap Class Loader：负责加载JAVA_HOME/lib目录下或-Xbootclasspath指定目录的jar包；"></a>1、Bootstrap Class Loader：负责加载JAVA_HOME/lib目录下或-Xbootclasspath指定目录的jar包；</h4><h4 id="2、Extention-Class-Loader：加载JAVA-HOME-lib-ext目录下的或-Djava-ext-dirs指定目录下的jar包。"><a href="#2、Extention-Class-Loader：加载JAVA-HOME-lib-ext目录下的或-Djava-ext-dirs指定目录下的jar包。" class="headerlink" title="2、Extention Class Loader：加载JAVA_HOME/lib/ext目录下的或-Djava.ext.dirs指定目录下的jar包。"></a>2、Extention Class Loader：加载JAVA_HOME/lib/ext目录下的或-Djava.ext.dirs指定目录下的jar包。</h4><h4 id="3、System-Class-Loader：加载classpath或者-Djava-class-path指定目录下的类或jar包。"><a href="#3、System-Class-Loader：加载classpath或者-Djava-class-path指定目录下的类或jar包。" class="headerlink" title="3、System Class Loader：加载classpath或者-Djava.class.path指定目录下的类或jar包。"></a>3、System Class Loader：加载classpath或者-Djava.class.path指定目录下的类或jar包。</h4><h4 id="ClassLoader各司其职-加载在不同路径下的class文件-值得注意的是-类加载采用的是双亲委托的设计模式-即传入一个类限定名-逐层向上到Bootstrap-Class-Loader中查找-如果找到即返回-若没有找到-则在Extention-Class-Loader中找-若还没有找到则在System-Class-Loader下找-即classpath中-如果还没有找到-则调用findClass-name-方法-执行用户自己的类加载逻辑-可能在其他的地方"><a href="#ClassLoader各司其职-加载在不同路径下的class文件-值得注意的是-类加载采用的是双亲委托的设计模式-即传入一个类限定名-逐层向上到Bootstrap-Class-Loader中查找-如果找到即返回-若没有找到-则在Extention-Class-Loader中找-若还没有找到则在System-Class-Loader下找-即classpath中-如果还没有找到-则调用findClass-name-方法-执行用户自己的类加载逻辑-可能在其他的地方" class="headerlink" title="ClassLoader各司其职,加载在不同路径下的class文件,值得注意的是,类加载采用的是双亲委托的设计模式,即传入一个类限定名,逐层向上到Bootstrap Class Loader中查找,如果找到即返回,若没有找到,则在Extention Class Loader中找,若还没有找到则在System Class Loader下找,即classpath中,如果还没有找到,则调用findClass(name)方法,执行用户自己的类加载逻辑(可能在其他的地方)"></a>ClassLoader各司其职,加载在不同路径下的class文件,值得注意的是,类加载采用的是双亲委托的设计模式,即传入一个类限定名,逐层向上到Bootstrap Class Loader中查找,如果找到即返回,若没有找到,则在Extention Class Loader中找,若还没有找到则在System Class Loader下找,即classpath中,如果还没有找到,则调用findClass(name)方法,执行用户自己的类加载逻辑(可能在其他的地方)</h4><h4 id="ClassLoader中的几个重要的方法："><a href="#ClassLoader中的几个重要的方法：" class="headerlink" title="ClassLoader中的几个重要的方法："></a>ClassLoader中的几个重要的方法：</h4><h4 id="1、loadClass-String-name-boolean-resolve-：加载类的方法，在jdk1-2以前需要重写该方法实现用户自己的逻辑，1-2以后为了向下兼容，仍然可以重写该方法，但是建议用户将自己的加载逻辑实现在findName（name）中。这样系统先向上寻找能否加载到该类-如果加在不到-将调用用户自定义的findName函数加载对象"><a href="#1、loadClass-String-name-boolean-resolve-：加载类的方法，在jdk1-2以前需要重写该方法实现用户自己的逻辑，1-2以后为了向下兼容，仍然可以重写该方法，但是建议用户将自己的加载逻辑实现在findName（name）中。这样系统先向上寻找能否加载到该类-如果加在不到-将调用用户自定义的findName函数加载对象" class="headerlink" title="1、loadClass(String name, boolean resolve)：加载类的方法，在jdk1.2以前需要重写该方法实现用户自己的逻辑，1.2以后为了向下兼容，仍然可以重写该方法，但是建议用户将自己的加载逻辑实现在findName（name）中。这样系统先向上寻找能否加载到该类,如果加在不到,将调用用户自定义的findName函数加载对象."></a>1、loadClass(String name, boolean resolve)：加载类的方法，在jdk1.2以前需要重写该方法实现用户自己的逻辑，1.2以后为了向下兼容，仍然可以重写该方法，但是建议用户将自己的加载逻辑实现在findName（name）中。这样系统先向上寻找能否加载到该类,如果加在不到,将调用用户自定义的findName函数加载对象.</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div></pre></td><td class="code"><pre><div class="line">/**</div><div class="line">  * @param name    类名字</div><div class="line">  * @param resolve 　是否解析，如果只是想知道该class是否存在可以设置该参数为false</div><div class="line">  * @return 返回一个class泛型</div><div class="line">  * @throws ClassNotFoundException</div><div class="line">  */</div><div class="line"> protected Class&lt;?&gt; loadClass(String name, boolean resolve)</div><div class="line">         throws ClassNotFoundException &#123;</div><div class="line">     /**</div><div class="line">      * getClassLoadingLock(name)</div><div class="line">      * 为类的加载操作返回一个锁对象。为了向后兼容，这个方法这样实现:如果当前的classloader对象注册了并行能力，</div><div class="line">      * 方法返回一个与指定的名字className相关联的特定对象，否则，直接返回当前的ClassLoader对象。</div><div class="line">      */</div><div class="line">     synchronized (getClassLoadingLock(name)) &#123;</div><div class="line">         // 首先查看class是否已经被加载过</div><div class="line">         Class&lt;?&gt; c = findLoadedClass(name);</div><div class="line">         if (c == null) &#123;</div><div class="line">             long t0 = System.nanoTime();</div><div class="line">             try &#123;</div><div class="line">                 //如果父加载器不为空，则委托给父加载器去加载</div><div class="line">                 if (parent != null) &#123;</div><div class="line">                     c = parent.loadClass(name, false);</div><div class="line">                 &#125; else &#123;</div><div class="line">                     /**</div><div class="line">                      *  如果父加载器为空，说明父加载器已经是Bootstrap ClassLoader了，则直接使用根加载器加载,也就是使用虚拟机加</div><div class="line">                      *  载器加载</div><div class="line">                      */</div><div class="line">                     c = findBootstrapClassOrNull(name);</div><div class="line">                 &#125;</div><div class="line">             &#125; catch (ClassNotFoundException e) &#123;</div><div class="line">                 // ClassNotFoundException thrown if class not found</div><div class="line">                 // from the non-null parent class loader</div><div class="line">             &#125;</div><div class="line">             //如果以上的加载器在自己的路径上面都没有加载到,则调用findClass(name)调用用户自定义的加载器</div><div class="line">             if (c == null) &#123;</div><div class="line">                 // If still not found, then invoke findClass in order</div><div class="line">                 // to find the class.</div><div class="line">                 long t1 = System.nanoTime();</div><div class="line">                 c = findClass(name);</div><div class="line"></div><div class="line">                 // this is the defining class loader; record the stats</div><div class="line">                 sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0);</div><div class="line">                 sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1);</div><div class="line">                 sun.misc.PerfCounter.getFindClasses().increment();</div><div class="line">             &#125;</div><div class="line">         &#125;</div><div class="line">         //根据resolve参数决定是否解析该类</div><div class="line">         if (resolve) &#123;</div><div class="line">             resolveClass(c);</div><div class="line">         &#125;</div><div class="line">         return c;</div><div class="line">     &#125;</div><div class="line"> &#125;</div></pre></td></tr></table></figure>
<h4 id="2、ClassLoader-getParent-可以返回委托的父类加载器。在你自定义加载器找不到相应类的时候，可以调用此方法，不过在ClassLoader的默认实现中，ClassLoader先判断父类加载器是否可以加载，然后再调用用户自定义的findClass方法。"><a href="#2、ClassLoader-getParent-可以返回委托的父类加载器。在你自定义加载器找不到相应类的时候，可以调用此方法，不过在ClassLoader的默认实现中，ClassLoader先判断父类加载器是否可以加载，然后再调用用户自定义的findClass方法。" class="headerlink" title="2、ClassLoader getParent() :可以返回委托的父类加载器。在你自定义加载器找不到相应类的时候，可以调用此方法，不过在ClassLoader的默认实现中，ClassLoader先判断父类加载器是否可以加载，然后再调用用户自定义的findClass方法。"></a>2、ClassLoader getParent() :可以返回委托的父类加载器。在你自定义加载器找不到相应类的时候，可以调用此方法，不过在ClassLoader的默认实现中，ClassLoader先判断父类加载器是否可以加载，然后再调用用户自定义的findClass方法。</h4><h4 id="3、-resolveClass-若resolve参数为true的时候，我们需要调用该函数，resolve我们的classLoader。"><a href="#3、-resolveClass-若resolve参数为true的时候，我们需要调用该函数，resolve我们的classLoader。" class="headerlink" title="3、 resolveClass():若resolve参数为true的时候，我们需要调用该函数，resolve我们的classLoader。"></a>3、 resolveClass():若resolve参数为true的时候，我们需要调用该函数，resolve我们的classLoader。</h4><h4 id="4、ClassLoader-getSystemClassLoader-提供了一个直接访问系统classloader的方法。"><a href="#4、ClassLoader-getSystemClassLoader-提供了一个直接访问系统classloader的方法。" class="headerlink" title="4、ClassLoader getSystemClassLoader():提供了一个直接访问系统classloader的方法。"></a>4、ClassLoader getSystemClassLoader():提供了一个直接访问系统classloader的方法。</h4><h1 id="3、废话少说上代码！"><a href="#3、废话少说上代码！" class="headerlink" title="3、废话少说上代码！"></a>3、废话少说上代码！</h1><h4 id="下面我将以一个例子来阐述如何使用ClassLoader，自定义的ClassLoader将加载被加密的类，而且这个类存储的路径不在ClassPath中，也不可以被Bootstrap-Class-Loader和Extention-Class-Loader加载，在实际应用中，可以是网络中传递过来的加密字节流，抑或着是实现脚本的热部署操作。"><a href="#下面我将以一个例子来阐述如何使用ClassLoader，自定义的ClassLoader将加载被加密的类，而且这个类存储的路径不在ClassPath中，也不可以被Bootstrap-Class-Loader和Extention-Class-Loader加载，在实际应用中，可以是网络中传递过来的加密字节流，抑或着是实现脚本的热部署操作。" class="headerlink" title="下面我将以一个例子来阐述如何使用ClassLoader，自定义的ClassLoader将加载被加密的类，而且这个类存储的路径不在ClassPath中，也不可以被Bootstrap Class Loader和Extention Class Loader加载，在实际应用中，可以是网络中传递过来的加密字节流，抑或着是实现脚本的热部署操作。"></a>下面我将以一个例子来阐述如何使用ClassLoader，自定义的ClassLoader将加载被加密的类，而且这个类存储的路径不在ClassPath中，也不可以被Bootstrap Class Loader和Extention Class Loader加载，在实际应用中，可以是网络中传递过来的加密字节流，抑或着是实现脚本的热部署操作。</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div></pre></td><td class="code"><pre><div class="line">package com.siyu;</div><div class="line"></div><div class="line"></div><div class="line">import java.io.*;</div><div class="line"></div><div class="line">public class ClassLoaderTest extends ClassLoader &#123;</div><div class="line">    //自定义加载器加载该路径下面的文件</div><div class="line">    private String directory;</div><div class="line"></div><div class="line">    public ClassLoaderTest(String directory) &#123;</div><div class="line">        this.directory = directory;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    /**</div><div class="line">     * 重写findClass,用户可以做以下的事情</div><div class="line">     * 1.可以加载boot、ext、system加载器所加载不了的路径下的文件</div><div class="line">     * 2.可以解密加密后的class文件</div><div class="line">     */</div><div class="line">    @Override</div><div class="line">    protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123;</div><div class="line">        //解密密钥</div><div class="line">        byte key = (byte) 1;</div><div class="line">        //加密文件的路径</div><div class="line">        String fileName = directory + name + &quot;.class&quot;;</div><div class="line">        File file = new File(fileName);</div><div class="line">        byte[] decryptedByte = readFromFile(file);</div><div class="line">        //解密为原始的class文件</div><div class="line">        for (int i = 0; i &lt; decryptedByte.length; i++) &#123;</div><div class="line">            decryptedByte[i] = (byte) (decryptedByte[i] ^ key);</div><div class="line">        &#125;</div><div class="line">        //defineClass实现了链接阶段的验证等</div><div class="line">        return defineClass(null, decryptedByte, 0, decryptedByte.length);</div><div class="line">    &#125;</div><div class="line"></div><div class="line"></div><div class="line">    private byte[] readFromFile(File fileName) &#123;</div><div class="line">        try &#123;</div><div class="line">            byte[] bytes = null;</div><div class="line">            FileInputStream fin = new FileInputStream(fileName);</div><div class="line"></div><div class="line">            int i;</div><div class="line">            if ((i = fin.read()) != -1) &#123;</div><div class="line">                //初始化数组大小和文件大小一样</div><div class="line">                bytes = new byte[fin.available()];</div><div class="line">                fin.read(bytes);</div><div class="line">            &#125;</div><div class="line">            return bytes;</div><div class="line">        &#125; catch (FileNotFoundException e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">            return null;</div><div class="line">        &#125; catch (IOException e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">            return null;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    private byte[] encrypt(byte[] bytes) &#123;</div><div class="line">        byte key = (byte) 1;</div><div class="line">        //依次加密的代码</div><div class="line">        for (int i = 0; i &lt; bytes.length; i++) &#123;</div><div class="line">            bytes[i] = (byte) (bytes[i] ^ key); //利用异或加密</div><div class="line">        &#125;</div><div class="line">        return bytes;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    public void encryptFile(String fileName, String directory) &#123;</div><div class="line">        try &#123;</div><div class="line">            String name = fileName.substring(fileName.lastIndexOf(&quot;\\&quot;) + 1, fileName.length() - 6);</div><div class="line">            //加密文件的路径</div><div class="line">            String destFileName = directory + &quot;encryted&quot; + name + &quot;.class&quot;;</div><div class="line">            //如果加密文件不存在则创建加密文件</div><div class="line">            File f = new File(destFileName);</div><div class="line">            if (f == null) &#123;</div><div class="line">                f.createNewFile();</div><div class="line">            &#125;</div><div class="line">            //加密</div><div class="line">            byte[] encryptedByte = encrypt(readFromFile(new File(fileName)));</div><div class="line">            FileOutputStream fos = new FileOutputStream(destFileName);</div><div class="line">            //把加密后的字节写入到加密文件中</div><div class="line">            fos.write(encryptedByte);</div><div class="line">        &#125; catch (FileNotFoundException e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125; catch (IOException e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line"></div><div class="line">    public static void main(String[] args) &#123;</div><div class="line">        //设置加密路径</div><div class="line">        ClassLoaderTest classLoaderTest=new ClassLoaderTest(&quot;C:\\EncryptedClass\\&quot;);</div><div class="line">        //将test.class加密后存储到EncryptedClass目录下</div><div class="line">        classLoaderTest.encryptFile(&quot;C:\\Users\\jasonchu.zsy\\IdeaProjects\\BoKeTest\\out\\production\\BoKeTest\\com\\siyu\\test.class&quot;</div><div class="line">                ,&quot;C:\\EncryptedClass\\&quot;);</div><div class="line">        try &#123;</div><div class="line">            Class&lt;?&gt; t=classLoaderTest.loadClass(&quot;encrytedtest&quot;);</div><div class="line">        &#125; catch (ClassNotFoundException e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="在main函数中先将一个编译好的class文件加密后存储在非classpath路径下，然后用自定义classLoader进行加载，加密为了简单起见，使用的是异或加密，利用的原理是二进制的数经过两次异或操作后得到的值是相同的。路径也使用的绝对路径，大家可以根据需要自行进行修改，有什么问题可以继续交流，谢谢。"><a href="#在main函数中先将一个编译好的class文件加密后存储在非classpath路径下，然后用自定义classLoader进行加载，加密为了简单起见，使用的是异或加密，利用的原理是二进制的数经过两次异或操作后得到的值是相同的。路径也使用的绝对路径，大家可以根据需要自行进行修改，有什么问题可以继续交流，谢谢。" class="headerlink" title="在main函数中先将一个编译好的class文件加密后存储在非classpath路径下，然后用自定义classLoader进行加载，加密为了简单起见，使用的是异或加密，利用的原理是二进制的数经过两次异或操作后得到的值是相同的。路径也使用的绝对路径，大家可以根据需要自行进行修改，有什么问题可以继续交流，谢谢。"></a>在main函数中先将一个编译好的class文件加密后存储在非classpath路径下，然后用自定义classLoader进行加载，加密为了简单起见，使用的是异或加密，利用的原理是二进制的数经过两次异或操作后得到的值是相同的。路径也使用的绝对路径，大家可以根据需要自行进行修改，有什么问题可以继续交流，谢谢。</h4>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/08/02/class/" data-id="cj8brusrz0001881n9jfhz4tw" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">September 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">August 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/09/03/distributed/">分布式资源管理</a>
          </li>
        
          <li>
            <a href="/2017/08/05/tensor/">TensorFlow Tutorial-1</a>
          </li>
        
          <li>
            <a href="/2017/08/03/callback/">JAVA回调机制(CallBack)详解</a>
          </li>
        
          <li>
            <a href="/2017/08/02/class/">ClassLoader和类加载机制</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 Jason Chu<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>